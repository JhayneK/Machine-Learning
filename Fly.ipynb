import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import GridSearchCV
from sklearn import preprocessing
from sklearn.datasets import load_diabetes
from sklearn.model_selection import cross_val_score
from sklearn.tree import DecisionTreeRegressor
X, y = load_diabetes(return_X_y=True)
regressor = DecisionTreeRegressor(random_state=0)
cross_val_score(regressor, X, y, cv=10)




# Realização da leitura do arquivo
dataframe = pd.read_excel('Data_Train.xlsx', index_col=False)
# Dropando colunas que não serão utilizadas
dataframe.drop(['Dep_Time', 'Arrival_Time', 'Total_Stops', 'Additional_Info'], axis = 1, inplace = True)
# Eliminando linhas que possuem dados nulos
dataframe.dropna(inplace=True)

# Nova seção

# Verificando nulidade das colunas
dataframe.isnull().sum()

# Coletando o tamanho do dataframe
dataframe.shape

# Airline = Ordinal
# Source = Ordinal
# Date_of_Journey = apenas o mês
# Destination = Ordinal
# Route = número de paradas
# Duration = converter para um valor numérico (minutos)

dataframe['Route'] = dataframe['Route'].str.count('→')
dataframe['Duration'] = dataframe['Duration'].apply(lambda x: int(x.split()[0][:-1])*60 + int(x.split()[1][:-1]) if 'h' in x and 'm' in x else (int(x.split()[0][:-1]) * 60 if 'h' in x else int(x.split()[0][:-1])))
dataframe['Date_of_Journey'] = pd.to_datetime(dataframe['Date_of_Journey'], format='%d/%m/%Y')
dataframe['Date_of_Journey'] = dataframe['Date_of_Journey'].dt.month

encoder = preprocessing.OrdinalEncoder()
dataframe['Airline'] = encoder.fit_transform(dataframe[['Airline']])
dataframe['Source'] = encoder.fit_transform(dataframe[['Source']])
dataframe['Destination'] = encoder.fit_transform(dataframe[['Destination']])

n_estimators



# Pré-processamento do conjunto de dados
preprocessor = ColumnTransformer(
    transformers=[
        ('cat', categorical_transformer, categorical_cols),
        ('num', StandardScaler(), ['Route', 'Duration', 'Date_of_Journey'])
    ])

# Definindo o modelo RandomForestRegressor
model = RandomForestRegressor()

# Criando o pipeline
pipeline = Pipeline(steps=[('preprocessor', preprocessor),
                           ('model', model)])

# Defina X e y
x = dataframe.drop(['Price'], axis=1)
y = dataframe['Price']

# Divida o conjunto de dados em treino e teste
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

# Parâmetros para a busca em grade
param_grid = {
    'model__n_estimators': [50, 100, 200],
    'model__max_depth': [None, 10, 20, 30],
    #'model__min_samples_split': [2, 5, 10],
    #'model__min_samples_leaf': [1, 2, 4]
}

# Configurando a busca em grade
grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)

# Treinando o modelo
grid_search.fit(x_train, y_train)

# Avaliando o modelo
print("Melhores parâmetros:", grid_search.best_params_)
print("Melhor pontuação (neg_mean_squared_error):", grid_search.best_score_)

# Avaliação no conjunto de teste
test_score = grid_search.score(x_test, y_test)
print("Pontuação no conjunto de teste (neg_mean_squared_error):", test_score)

